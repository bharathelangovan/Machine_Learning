{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.cross_validation import KFold\n",
    "%matplotlib inline\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Multiple Feature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    r = io.open(filename, encoding='utf8').readlines()\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in r:\n",
    "        if i.split()[0] != '#':\n",
    "            tmp = i.split()\n",
    "            X.append([float(tmp[o]) for o in range(len(tmp)-1)])\n",
    "            Y.append([float(tmp[-1])])\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Map  to Higher Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_high_dimension(Data,degree):\n",
    "    polyfeat_object = PolynomialFeatures(degree)\n",
    "    hd_data = polyfeat_object.fit_transform(Data)\n",
    "    return hd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Matrix mapped to Higher dimemsion of degree 3\n",
      "[[  1.00000000e+00   1.67346939e+00   4.48979592e-01 ...,   1.25736725e+00\n",
      "    3.37342434e-01   9.05065066e-02]\n",
      " [  1.00000000e+00  -4.08163265e-02   5.30612245e-01 ...,   8.83985414e-04\n",
      "   -1.14918104e-02   1.49393535e-01]\n",
      " [  1.00000000e+00  -7.75510204e-01  -1.59183673e+00 ...,  -9.57356204e-01\n",
      "   -1.96509958e+00  -4.03362545e+00]\n",
      " ..., \n",
      " [  1.00000000e+00  -2.00000000e+00  -6.93877551e-01 ...,  -2.77551020e+00\n",
      "   -9.62932112e-01  -3.34078488e-01]\n",
      " [  1.00000000e+00  -1.83673469e+00   1.02040816e+00 ...,   3.44244320e+00\n",
      "   -1.91246844e+00   1.06248247e+00]\n",
      " [  1.00000000e+00  -2.85714286e-01   1.42857143e+00 ...,   1.16618076e-01\n",
      "   -5.83090379e-01   2.91545190e+00]]\n"
     ]
    }
   ],
   "source": [
    "Z,Y = read_file(\"mvar-set1.dat.txt\")\n",
    "degrees = [2,3,4,5,6]\n",
    "Z_hd_dictionary = {}\n",
    "for i in degrees:\n",
    "    Z_hd_dictionary[i] = map_high_dimension(Z,i)\n",
    "print \"Data Matrix mapped to Higher dimemsion of degree 3\"\n",
    "print Z_hd_dictionary[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Theta - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_theta(Data,Labels):\n",
    "    return np.dot(np.linalg.pinv(Data),np.array(Labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(t,z):\n",
    "    predictions = []\n",
    "    for i in z:\n",
    "        predictions.append(np.dot(t.transpose(),np.array(i)))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mean_square_error(pred,y):\n",
    "    return sum([(i-j)**2 for i,j in zip(pred,y)])/len(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Theta for all High Dimension Feature Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta value of high dimensional data set of degree 3\n",
      "[[  1.02230218e+00]\n",
      " [  1.00248539e+00]\n",
      " [  1.00537442e+00]\n",
      " [ -1.26097513e-02]\n",
      " [ -8.47393334e-03]\n",
      " [ -6.43213699e-03]\n",
      " [ -2.31159943e-03]\n",
      " [ -1.64092663e-02]\n",
      " [  5.84897669e-04]\n",
      " [  3.15715316e-03]]\n"
     ]
    }
   ],
   "source": [
    "Z_hd_theta = {}\n",
    "for i in Z_hd_dictionary:\n",
    "    Z_hd_theta[i] = find_theta(Z_hd_dictionary[i],Y)\n",
    "print \"Theta value of high dimensional data set of degree 3\"\n",
    "print Z_hd_theta[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Using the Theta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted and actual values of high dimensional data set of degree 3(first 25 values)\n",
      "Predcited\t\tActual\n",
      "[ 3.07736342] \t\t[2.861980967575097]\n",
      "[ 1.51365053] \t\t[0.5195252261416367]\n",
      "[-1.38696723] \t\t[-2.245760962347731]\n",
      "[-2.32471805] \t\t[-1.561989674513609]\n",
      "[ 1.34557589] \t\t[1.887592936186108]\n",
      "[ 1.22770058] \t\t[0.9884311316371547]\n",
      "[-1.44192419] \t\t[-1.085317769937612]\n",
      "[ 1.29287274] \t\t[0.8038785273144268]\n",
      "[ 2.49595503] \t\t[3.18204127016383]\n",
      "[ 2.53802138] \t\t[2.351083268524211]\n",
      "[ 3.51292129] \t\t[3.626071229401944]\n",
      "[-0.17188473] \t\t[0.4634078745339167]\n",
      "[ 0.85542858] \t\t[1.487055672161672]\n",
      "[ 2.3113871] \t\t[2.142605152020115]\n",
      "[-0.46229492] \t\t[-1.110575348573327]\n",
      "[ 3.10202926] \t\t[3.929068438319104]\n",
      "[-1.94229288] \t\t[-1.927879404879771]\n",
      "[-0.56049346] \t\t[-0.1816051916186905]\n",
      "[ 1.90961133] \t\t[1.71526336810711]\n",
      "[ 0.62064496] \t\t[0.7650547285963669]\n",
      "[-0.87883622] \t\t[-1.280690811878441]\n",
      "[ 3.69919814] \t\t[3.876430712322037]\n",
      "[ 0.59320767] \t\t[0.5123972650771516]\n",
      "[ 0.42276492] \t\t[0.3184214808888129]\n",
      "[ 2.76858808] \t\t[2.495057994255536]\n"
     ]
    }
   ],
   "source": [
    "Y_hd_predict = {}\n",
    "for i in Z_hd_dictionary:\n",
    "    Y_hd_predict[i] = predict(Z_hd_theta[i],Z_hd_dictionary[i])\n",
    "print \"Predicted and actual values of high dimensional data set of degree 3(first 25 values)\"\n",
    "print \"Predcited\\t\\tActual\"\n",
    "for i in range(25):\n",
    "    print Y_hd_predict[3][i],\"\\t\\t\",Y[i]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Mean Square Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Errors of High Dimensional feature space\n",
      "Degree\tMSE\n",
      "2 \t0.258256248391\n",
      "3 \t0.257655351948\n",
      "4 \t0.256493824893\n",
      "5 \t0.256237649361\n",
      "6 \t0.255132612013\n"
     ]
    }
   ],
   "source": [
    "MSE_mean ={}\n",
    "for i in Y_hd_predict:\n",
    "    MSE_mean[i] = mean_square_error(Y_hd_predict[i],Y)\n",
    "print \"Mean Square Errors of High Dimensional feature space\"    \n",
    "print\"Degree\\tMSE\"\n",
    "for i in MSE_mean:\n",
    "    print i,\"\\t\",MSE_mean[i][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation for n folds using manualy created fit and predict functions; Finding the Training Error and Testing Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fold_indices(size, folds):\n",
    "    block_list = [size//folds for i in range(folds)]\n",
    "    if size%folds != 0:\n",
    "        for i in range(size%folds):\n",
    "            block_list[i] += 1\n",
    "    current = 0\n",
    "    indices = []\n",
    "    for x in block_list:\n",
    "        m,n = current, current + x\n",
    "        indices.append((m,n))\n",
    "        current = n\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cross_validation(data,labels,folds):\n",
    "    k_index = fold_indices(len(labels), folds)\n",
    "    Theta_list = []\n",
    "    training_MSE_list =[]\n",
    "    testing_MSE_list = []\n",
    "    for i in k_index:\n",
    "        Z_test = data[i[0]:i[1]]\n",
    "        Y_test = labels[i[0]:i[1]]\n",
    "        Z_train = np.ndarray([])\n",
    "        Y_train = np.ndarray([])\n",
    "        for j in k_index:\n",
    "            if i != j:\n",
    "                Z_train = Z_train + data[j[0]:j[1]]\n",
    "                Y_train = Y_train + labels[j[0]:j[1]]\n",
    "        Theta  = find_theta(Z_train,Y_train)\n",
    "        training_MSE = mean_square_error(predict(Theta,Z_train), Y_train)\n",
    "        pred = predict(Theta,Z_test)\n",
    "        MSE = mean_square_error(pred, Y_test)\n",
    "        Theta_list.append(Theta)\n",
    "        testing_MSE_list.append(MSE)\n",
    "        training_MSE_list.append(training_MSE)\n",
    "    return Theta_list, testing_MSE_list, training_MSE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training Errot and Testing Error for Linear Regression on High Dimensional Feature Space of degree 6 for 10 folds\n",
      "Training Error\tTesting Error\n",
      "1.721218\t2.025014\n",
      "5.277094\t2.139538\n",
      "6.931781\t2.052602\n",
      "7.224948\t2.054735\n",
      "8.520127\t2.129154\n",
      "7.227964\t1.953868\n",
      "7.575019\t2.151559\n",
      "7.194835\t2.074939\n",
      "8.557931\t2.150347\n",
      "7.581050\t2.147773\n"
     ]
    }
   ],
   "source": [
    "thetas,test_mse,training_mse = cross_validation(Z_hd_dictionary[6],Y,10)\n",
    "print(\"The Training Errot and Testing Error for Linear Regression on High Dimensional Feature Space of degree 6 for 10 folds\")\n",
    "print(\"Training Error\\tTesting Error\")\n",
    "for i in range(len(training_mse)):\n",
    "    print \"%f\\t%f\" %(test_mse[i][0],training_mse[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradient_descent(z, y, theta_assume, learning_rate, interation_count):\n",
    "    theta = np.ones(len(z[0]))\n",
    "    theta.fill(theta_assume)\n",
    "    for i in range(interation_count):\n",
    "        pred = predict(theta,z)\n",
    "        sumtheta = np.zeros(len(z[0]))\n",
    "        for i in range(len(pred)):\n",
    "            sumtheta = sumtheta + ((pred[i] - y[i])*z[i])\n",
    "        theta = theta - learning_rate*sumtheta\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xy =gradient_descent(Z_hd_dictionary[3][0:2000], Y[0:2000], 0.1, 0.00005, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.01512903,  1.00395836,  0.98701184, -0.01487465, -0.01156393,\n",
       "       -0.00260941, -0.00413616, -0.01150208,  0.00471191,  0.00403633])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data,test_data = Z_hd_dictionary[3][0:2000],Z_hd_dictionary[3][2000:]\n",
    "train_y,test_y = Y[0:2000],Y[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def iterative_solution(z, y, theta_assume, learning_rate, interation_count,z_test):\n",
    "    theta_grad =gradient_descent(z, y, theta_assume, learning_rate, interation_count)\n",
    "    pred_is = predict(np.array(theta_grad),z_test)\n",
    "    print theta_grad\n",
    "    return pred_is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def explicit_solution(z, y,z_test):\n",
    "    theta_es = find_theta(z,y)\n",
    "    print theta_es\n",
    "    pred_es = predict(theta_es,z_test)\n",
    "    return pred_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.01512903  1.00395836  0.98701184 -0.01487465 -0.01156393 -0.00260941\n",
      " -0.00413616 -0.01150208  0.00471191  0.00403633]\n",
      "[1.2453408053522952, 1.1140300544616561, -2.0256944149678606, 1.1825210696628787, 1.4754847039209054, -2.1153502532509045, 1.3052016163516986, 1.0352919283873321, 3.5184167498795911, 0.92894920536244963, 0.22070448774998377, 2.223974873624929, -1.7970791341422869, 2.8363442388821634, -0.58256830181926789, -0.28988428190842863, 2.9855461158733396, -0.37337414156988752, -2.7702348477503196, 2.4529754146273972, 1.347953967461883, 0.28624968163769982, 0.83056805479630702, 3.663961493802558, 0.13060148090415388, 2.3042645280978515, -0.088237048261898043, 3.3646871534739082, 1.4092915456051516, -0.54152881081404447, -0.48883290767341009, 4.4251144759797496, -1.7865229914566298, 2.2246528174791886, 0.12177889890497418, 3.3140330597593146, -2.5369110826153802, -0.61779266030688085, 0.069726638729551191, 1.9024477634253296, 2.3857084743103907, 0.10832136002332501, 1.8210083504857824, 0.35542558624348308, 4.7601559129812063, -1.126943160735796, 0.12892233725696747, 0.49710035144533077, -1.5415542090429544, 3.9411642896348509]\n"
     ]
    }
   ],
   "source": [
    "print iterative_solution(train_data, train_y, 0.1, 0.00005, 600,test_data)[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.01512825]\n",
      " [ 1.0039924 ]\n",
      " [ 0.98704724]\n",
      " [-0.01487432]\n",
      " [-0.01156381]\n",
      " [-0.00260912]\n",
      " [-0.0041459 ]\n",
      " [-0.01150636]\n",
      " [ 0.00470772]\n",
      " [ 0.00402614]]\n",
      "[array([ 1.24534673]), array([ 1.11402977]), array([-2.02569626]), array([ 1.18252498]), array([ 1.47548655]), array([-2.11535095]), array([ 1.30520167]), array([ 1.03529078]), array([ 3.5184259]), array([ 0.92894607]), array([ 0.2207029]), array([ 2.22397577]), array([-1.79708893]), array([ 2.83637781]), array([-0.58255668]), array([-0.28991568]), array([ 2.98557441]), array([-0.37340754]), array([-2.77017439]), array([ 2.45301157]), array([ 1.3479599]), array([ 0.28622658]), array([ 0.83058148]), array([ 3.66397428]), array([ 0.13058729]), array([ 2.30430027]), array([-0.08823855]), array([ 3.36470811]), array([ 1.40930116]), array([-0.54156879]), array([-0.48883915]), array([ 4.42507302]), array([-1.78654268]), array([ 2.22468664]), array([ 0.12175181]), array([ 3.31406803]), array([-2.53687717]), array([-0.61778262]), array([ 0.06975406]), array([ 1.902463]), array([ 2.38568653]), array([ 0.10829498]), array([ 1.82103043]), array([ 0.35540495]), array([ 4.7600801]), array([-1.12696216]), array([ 0.12890518]), array([ 0.49712559]), array([-1.54158009]), array([ 3.94117158])]\n"
     ]
    }
   ],
   "source": [
    "print explicit_solution(train_data, train_y,test_data)[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Kernal Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kernel_gram_matrix(x,y,sigma):\n",
    "    d = cdist(x,y,'sqeuclidean')    \n",
    "    return np.exp((-1/2)*(d/sigma**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kernel_weights(gram,labels):\n",
    "    return np.linalg.solve(gram,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian_predict(alpha,x,x_sample,sigma):\n",
    "    kernel_sample = kernel_gram_matrix(x,x_sample,sigma)\n",
    "    return np.dot(alpha.transpose(),kernel_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian_fit(x,y,sigma):\n",
    "    G = kernel_gram_matrix(x,x,sigma)\n",
    "    alpha = kernel_weights(G,y)\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian_theta(alpha,x):\n",
    "    return np.dot(alpha.transpose(),x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.39499829]\n",
      " [-0.61700647]\n",
      " [-2.10648385]\n",
      " [-1.55336294]\n",
      " [ 0.94903295]\n",
      " [ 0.97338585]\n",
      " [-0.96511813]\n",
      " [ 0.80051309]\n",
      " [ 2.99515497]\n",
      " [ 1.82511589]\n",
      " [ 3.48163753]\n",
      " [ 0.48699148]\n",
      " [ 0.80591897]\n",
      " [ 1.97621425]\n",
      " [-1.00537791]\n",
      " [ 3.6091703 ]\n",
      " [-1.91318885]\n",
      " [ 0.14868346]\n",
      " [ 0.46777488]\n",
      " [ 0.76375698]\n",
      " [-1.17075398]\n",
      " [ 3.8133481 ]\n",
      " [ 0.28796778]\n",
      " [ 0.32171543]\n",
      " [ 2.12579566]\n",
      " [ 1.57983271]\n",
      " [ 1.20248007]\n",
      " [ 0.17015024]\n",
      " [-0.30118843]\n",
      " [ 2.13755283]\n",
      " [-1.5336172 ]\n",
      " [ 0.75463089]\n",
      " [ 1.4996998 ]\n",
      " [ 1.34419739]\n",
      " [-0.81658818]\n",
      " [-0.23977971]\n",
      " [ 2.04633209]\n",
      " [ 1.32937515]\n",
      " [ 0.71692488]\n",
      " [ 0.64235499]\n",
      " [-0.02211506]\n",
      " [-1.16172165]\n",
      " [-0.39254188]\n",
      " [-1.13943073]\n",
      " [-1.11250928]\n",
      " [-0.99161622]\n",
      " [-1.64664593]\n",
      " [ 0.84908324]\n",
      " [-2.10676256]\n",
      " [-1.21048872]]\n"
     ]
    }
   ],
   "source": [
    "alpha = gaussian_fit(Z_hd_dictionary[2],Y,0.11111)\n",
    "print alpha[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.86198097  0.51952523 -2.24576096 ..., -0.66468951 -0.10755482\n",
      "   2.20162969]]\n"
     ]
    }
   ],
   "source": [
    "predd = gaussian_predict(alpha,Z_hd_dictionary[2],Z_hd_dictionary[2],0.11111)\n",
    "print predd[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error\n",
      "[  4.90950493e-27]\n"
     ]
    }
   ],
   "source": [
    "zz = 0\n",
    "for i in range(len(predd.transpose())):\n",
    "    cv = (predd.transpose()[i] - Y[i])**2\n",
    "    zz = zz + cv\n",
    "print \"Mean Error\"\n",
    "print zz/len(predd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
